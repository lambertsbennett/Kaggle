{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "tf.keras.backend.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Data/train.csv\")\n",
    "\n",
    "target = train_data['label']\n",
    "train_vars = train_data.drop(['label'],axis=1)\n",
    "\n",
    "X_train = train_vars/255\n",
    "y = target\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"kannada_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 26, 26, 32)   320         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 26, 26, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 64)   18496       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 24, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 64)     36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 64)     36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 64)     0           conv2d_7[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 6, 6, 64)     36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          16640       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 298,186\n",
      "Trainable params: 297,354\n",
      "Non-trainable params: 832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_3_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_4_output = layers.add([x, block_3_output])\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(block_4_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='kannada_resnet')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=8)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=1,factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 105s 2ms/sample - loss: 0.1741 - accuracy: 0.9447 - val_loss: 3.6545 - val_accuracy: 0.3485\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 108s 2ms/sample - loss: 0.0335 - accuracy: 0.9910 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 110s 2ms/sample - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0423 - val_accuracy: 0.9899\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 108s 2ms/sample - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 107s 2ms/sample - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 107s 2ms/sample - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0215 - val_accuracy: 0.9942\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 108s 2ms/sample - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0715 - val_accuracy: 0.9870\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0698 - val_accuracy: 0.9867\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0313 - val_accuracy: 0.9934\n",
      "Epoch 10/50\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0444 - val_accuracy: 0.9915\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0275 - val_accuracy: 0.9958\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0282 - val_accuracy: 0.9962\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 104s 2ms/sample - loss: 7.2116e-04 - accuracy: 0.9999 - val_loss: 0.0299 - val_accuracy: 0.9964\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4abe2bd810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,np.array(y),\n",
    "          epochs=50,validation_split=0.2,\n",
    "         batch_size=128, shuffle=True,callbacks =[lr_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('Data/test.csv')\n",
    "ImageId = test_data['id']\n",
    "NN_test = test_data.drop(['id'],axis=1)\n",
    "NN_test = NN_test/255\n",
    "NN_test = NN_test.values.reshape(NN_test.shape[0],28,28,1)\n",
    "\n",
    "predictions = np.argmax(model.predict(NN_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id':ImageId, 'label':predictions})\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
