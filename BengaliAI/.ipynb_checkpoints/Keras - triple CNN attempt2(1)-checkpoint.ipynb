{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 7\n",
    "inputs = keras.Input(shape=(137, 236, 1), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_outputs, activation='softmax')(x)\n",
    "\n",
    "model_consdia = keras.Model(inputs, outputs, name='bengali_consdia')\n",
    "model_consdia.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_consdia.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=8)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=1,factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"/kaggle/input/bengaliai-cv19/train.csv\")\n",
    "def batch_train_preprocess_consdia():\n",
    "    for filepath in glob.iglob(r'/kaggle/input/bengaliai-cv19/train*.parquet'):\n",
    "        train = pd.read_parquet(filepath)\n",
    "        train_image_id = train.image_id\n",
    "        train.drop(columns=['image_id'],inplace=True)\n",
    "        \n",
    "        train_image_id = pd.DataFrame(train_image_id, columns=['image_id'])\n",
    "        labels = pd.merge(train_image_id,train_labels, on='image_id')\n",
    "        y = labels['consonant_diacritic']\n",
    "        train_data = train.values.reshape(train.shape[0],137,236,1)\n",
    "        \n",
    "        model_consdia.fit(train_data,np.array(y),\n",
    "              epochs=80,validation_split=0.2,batch_size=128, shuffle=True,callbacks =[lr_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train_preprocess_consdia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 11\n",
    "\n",
    "inputs = keras.Input(shape=(137, 236, 1), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_outputs, activation='softmax')(x)\n",
    "\n",
    "model_vdia = keras.Model(inputs, outputs, name='bengali_vowel_dia')\n",
    "model_vdia.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"best_v_diacritic_model.hdf5\"\n",
    "#check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "#                              save_best_only = True, mode = \"min\")\n",
    "\n",
    "model_vdia.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=8)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=1,factor=0.2)\n",
    "\n",
    "def batch_train_preprocess_vowdia():\n",
    "    for filepath in glob.iglob(r'/kaggle/input/bengaliai-cv19/train*.parquet'):\n",
    "        train = pd.read_parquet(filepath)\n",
    "        train_image_id = train.image_id\n",
    "        train.drop(columns=['image_id'],inplace=True)\n",
    "        \n",
    "        train_image_id = pd.DataFrame(train_image_id, columns=['image_id'])\n",
    "        labels = pd.merge(train_image_id,train_labels, on='image_id')\n",
    "        y = labels['vowel_diacritic']\n",
    "        train_data = train.values.reshape(train.shape[0],137,236,1)\n",
    "        \n",
    "        model_vdia.fit(train_data,np.array(y),\n",
    "              epochs=80,validation_split=0.2,batch_size=128, shuffle=True,callbacks =[lr_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train_preprocess_consdiareprocess_vowdia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 168\n",
    "\n",
    "inputs = keras.Input(shape=(137, 236, 1), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_outputs, activation='softmax')(x)\n",
    "\n",
    "model_grapheme = keras.Model(inputs, outputs, name='bengali_grapheme_root')\n",
    "model_grapheme.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grapheme.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=8)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=1,factor=0.2)\n",
    "\n",
    "def batch_train_preprocess_grapheme():\n",
    "    for filepath in glob.iglob(r'/kaggle/input/bengaliai-cv19/train*.parquet'):\n",
    "        train = pd.read_parquet(filepath)\n",
    "        train_image_id = train.image_id\n",
    "        train.drop(columns=['image_id'],inplace=True)\n",
    "        \n",
    "        train_image_id = pd.DataFrame(train_image_id, columns=['image_id'])\n",
    "        labels = pd.merge(train_image_id,train_labels, on='image_id')\n",
    "        y = labels['grapheme_root']\n",
    "        train_data = train.values.reshape(train.shape[0],137,236,1)\n",
    "        \n",
    "        model_grapheme.fit(train_data,np.array(y),\n",
    "              epochs=80,validation_split=0.2,batch_size=128, shuffle=True,callbacks =[lr_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train_preprocess_grapheme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapheme = []\n",
    "con_dia = []\n",
    "vow_dia = []\n",
    "label = []\n",
    "\n",
    "for filepath in glob.iglob(r'/kaggle/input/bengaliai-cv19/test*.parquet'):\n",
    "    test = pd.read_parquet(filepath)\n",
    "    test_image_id = test.image_id\n",
    "    test.drop(columns=['image_id'],inplace=True)\n",
    "    test_data = test.values.reshape(test.shape[0],137,236,1)\n",
    "    label.append(test_image_id)\n",
    "    \n",
    "    con_dia.append(np.argmax(model_consdia.predict(test_data),axis=1))\n",
    "    vow_dia.append(np.argmax(model_vdia.predict(test_data),axis=1))\n",
    "    grapheme.append(np.argmax(model_grapheme.predict(test_data),axis=1))\n",
    "    \n",
    "res = pd.DataFrame({'row_id':label,'consonant_diacritic':con_dia,'grapheme_root':grapheme,'vowel_diacritic':vow_dia})\n",
    "res.to_csv('results.csv',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
